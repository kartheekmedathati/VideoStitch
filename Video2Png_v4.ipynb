{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import imutils\n",
    "import scipy\n",
    "from scipy import signal\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "# select the image id (valid values 1,2,3, or 4)\n",
    "feature_extractor = 'brisk' # one of 'sift', 'surf', 'brisk', 'orb'\n",
    "feature_matching = 'bf'\n",
    "\n",
    "def detectAndDescribe(image, method=None):\n",
    "    \"\"\"\n",
    "    Compute key points and feature descriptors using an specific method\n",
    "    \"\"\"\n",
    "    \n",
    "    assert method is not None, \"You need to define a feature detection method. Values are: 'sift', 'surf'\"\n",
    "    \n",
    "    # detect and extract features from the image\n",
    "    if method == 'sift':\n",
    "        descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "    elif method == 'surf':\n",
    "        descriptor = cv2.xfeatures2d.SURF_create()\n",
    "    elif method == 'brisk':\n",
    "        descriptor = cv2.BRISK_create()\n",
    "    elif method == 'orb':\n",
    "        descriptor = cv2.ORB_create()\n",
    "        \n",
    "    # get keypoints and descriptors\n",
    "    (kps, features) = descriptor.detectAndCompute(image, None)\n",
    "    \n",
    "    return (kps, features)\n",
    "\n",
    "def createMatcher(method,crossCheck):\n",
    "    \"Create and return a Matcher Object\"\n",
    "    \n",
    "    if method == 'sift' or method == 'surf':\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=crossCheck)\n",
    "    elif method == 'orb' or method == 'brisk':\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=crossCheck)\n",
    "    return bf\n",
    "\n",
    "def matchKeyPointsBF(featuresA, featuresB, method):\n",
    "    bf = createMatcher(method, crossCheck=True)\n",
    "        \n",
    "    # Match descriptors.\n",
    "    best_matches = bf.match(featuresA,featuresB)\n",
    "    \n",
    "    # Sort the features in order of distance.\n",
    "    # The points with small distance (more similarity) are ordered first in the vector\n",
    "    rawMatches = sorted(best_matches, key = lambda x:x.distance)\n",
    "    print(\"Raw matches (Brute force):\", len(rawMatches))\n",
    "    return rawMatches\n",
    "\n",
    "def matchKeyPointsKNN(featuresA, featuresB, ratio, method):\n",
    "    bf = createMatcher(method, crossCheck=False)\n",
    "    # compute the raw matches and initialize the list of actual matches\n",
    "    rawMatches = bf.knnMatch(featuresA, featuresB, 2)\n",
    "    print(\"Raw matches (knn):\", len(rawMatches))\n",
    "    matches = []\n",
    "\n",
    "    # loop over the raw matches\n",
    "    for m,n in rawMatches:\n",
    "        # ensure the distance is within a certain ratio of each\n",
    "        # other (i.e. Lowe's ratio test)\n",
    "        if m.distance < n.distance * ratio:\n",
    "            matches.append(m)\n",
    "    return matches\n",
    "\n",
    "def getHomography(kpsA, kpsB, featuresA, featuresB, matches, reprojThresh):\n",
    "    # convert the keypoints to numpy arrays\n",
    "    kpsA = np.float32([kp.pt for kp in kpsA])\n",
    "    kpsB = np.float32([kp.pt for kp in kpsB])\n",
    "    \n",
    "    if len(matches) > 4:\n",
    "\n",
    "        # construct the two sets of points\n",
    "        ptsA = np.float32([kpsA[m.queryIdx] for m in matches])\n",
    "        ptsB = np.float32([kpsB[m.trainIdx] for m in matches])\n",
    "        \n",
    "        # estimate the homography between the sets of points\n",
    "        #(H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC,reprojThresh)\n",
    "        (H, status) = cv2.estimateAffine2D(ptsA,ptsB,True)\n",
    "        H = np.vstack((H,[[0,0,1]]))\n",
    "        return (matches, H, status)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def warpTwoImages(img1, img2, H):\n",
    "    '''warp img2 to img1 with homograph H'''\n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    pts1 = np.array([[0,0],[0,h1],[w1,h1],[w1,0]],dtype=\"float32\").reshape(-1,1,2)\n",
    "    pts2 = np.array([[0,0],[0,h2],[w2,h2],[w2,0]],dtype=\"float32\").reshape(-1,1,2)\n",
    "    \n",
    "    print(\"Shape of:\",np.shape(pts1))\n",
    "    pts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "    #pts2_ = cv2.transform(pts2,H)\n",
    "    pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "    [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "    t = [-xmin,-ymin]\n",
    "    #Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
    "    Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]])\n",
    "    result = cv2.warpPerspective(img2, Ht.dot(H), (xmax-xmin, ymax-ymin),borderMode=cv2.BORDER_CONSTANT,borderValue=(255, 255, 255))\n",
    "    result[t[1]:h1+t[1],t[0]:w1+t[0]] =  img1\n",
    "    return result\n",
    "\n",
    "#Stich((img1)trainImg_gray, (img2)queryImg_gray,img1c, img2c,feature_extractor):\n",
    "def Stich(img1, img2, img1c, img2c,feature_extractor):\n",
    "    kpsA, featuresA = detectAndDescribe(img1, method=feature_extractor)\n",
    "    kpsB, featuresB = detectAndDescribe(img2, method=feature_extractor)\n",
    "    \n",
    "    if feature_matching == 'bf':\n",
    "        matches = matchKeyPointsBF(featuresA, featuresB, method=feature_extractor)\n",
    "        img3 = cv2.drawMatches(img1,kpsA,img2,kpsB,matches[:100],\n",
    "                               None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    elif feature_matching == 'knn':\n",
    "        matches = matchKeyPointsKNN(featuresA, featuresB, ratio=0.75, method=feature_extractor)\n",
    "        img3 = cv2.drawMatches(img1,kpsA,img2,kpsB,np.random.choice(matches,100),\n",
    "                               None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "        \n",
    "    M = getHomography(kpsA, kpsB, featuresA, featuresB, matches, reprojThresh=4)\n",
    "    if M is None:\n",
    "        print(\"Error!\")\n",
    "    (matches, H, status) = M\n",
    "    \n",
    "    #result = warpTwoImages(queryImg(img2c), trainImg(img1c), H)\n",
    "    result = warpTwoImages(img2c, img1c, H)\n",
    "    \n",
    "    gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # Finds contours from the binary image\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    \n",
    "    # get the maximum contour area\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "    # get a bbox from the contour area\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    # crop the image to the bbox coordinates\n",
    "    crop_pad = 0\n",
    "    result = result[y+crop_pad:y + h-crop_pad, x+crop_pad:x + w-crop_pad]\n",
    "    sva,svb,svc = np.linalg.svd(H[0:2,0:2])\n",
    "    s_ratio = svb[0]/svb[-1]\n",
    "    return result, s_ratio\n",
    "\n",
    "def AutoCrop(im):\n",
    "    img = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    m1 = cv2.Laplacian(img,cv2.CV_64F)\n",
    "    m1 = np.abs(m1)\n",
    "    p = np.var(m1,axis = 1)\n",
    "    p = scipy.signal.medfilt(p,11)\n",
    "    p[p<0.15]=0\n",
    "    \n",
    "    if len(np.nonzero(p)[0])==0:\n",
    "        return im\n",
    "    else:\n",
    "        l = np.max(np.nonzero(p)[0])\n",
    "        return im[0:l+1,:,:]\n",
    "\n",
    "\n",
    "def AutoCropLen(im):\n",
    "    img = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    m1 = cv2.Laplacian(img,cv2.CV_64F)\n",
    "    m1 = np.abs(m1)\n",
    "    p = np.var(m1,axis = 1)\n",
    "    p = scipy.signal.medfilt(p,11)\n",
    "    p[p<0.15]=0\n",
    "    if len(np.nonzero(p)[0])==0:\n",
    "        l = np.shape(img)[0]\n",
    "    else:\n",
    "        l = np.max(np.nonzero(p)[0])\n",
    "    return l\n",
    "\n",
    "def FrameSelect(im_list):\n",
    "    im_list = np.array(im_list)\n",
    "    level = 1 \n",
    "    no_of_images = len(im_list)\n",
    "    effective_len = np.zeros(no_of_images)\n",
    "    for i in range(0,no_of_images):\n",
    "        # Read files\n",
    "        fname1 = path + 'L'+str(level-1).zfill(2) + '_' + str(im_list[i]).zfill(5) + '.jpg'\n",
    "        ## AutoCrop to Eliminate White Spaces\n",
    "        trainImg = imageio.imread(fname1)\n",
    "        effective_len[i] = AutoCropLen(trainImg)\n",
    "    \n",
    "    d_len = np.diff(effective_len)\n",
    "    d_len[d_len>-5]=0\n",
    "    s_im_list = im_list[np.nonzero(d_len)[0]]\n",
    "    s_im_list = np.concatenate((s_im_list,[im_list[-1]]))\n",
    "    return s_im_list.tolist()\n",
    "\n",
    "    \n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def GenPairs(n):\n",
    "    p = []\n",
    "    n_p = int(np.floor(n/2))\n",
    "    for i in range(0, n_p):\n",
    "        p.append((2*i,2*i+1))\n",
    "    if n%2==1:\n",
    "        p.append((2*n_p-1,2*n_p))\n",
    "    return p\n",
    "\n",
    "def GenPairs(p_list):\n",
    "    n=len(p_list)\n",
    "    p = []\n",
    "    n_p = int(np.floor(n/2))\n",
    "    for i in range(0, n_p):\n",
    "        p.append((p_list[2*i],p_list[2*i+1]))\n",
    "    if n%2==1:\n",
    "        p.append((p_list[2*n_p-1],p_list[2*n_p]))\n",
    "    return p\n",
    "\n",
    "def Video2Png(n):    \n",
    "    level = 1\n",
    "    img_list = list(range(1,n+1))\n",
    "    #img_list = FrameSelect(img_list)\n",
    "    if n<=1:\n",
    "        print(\"Nothing to do.\")\n",
    "        return\n",
    "    while(n>1):\n",
    "        curr_pairs = GenPairs(img_list)\n",
    "        img_list = StichPairs(curr_pairs,level)\n",
    "        level = level+1\n",
    "        if len(img_list)<n:\n",
    "            n = len(img_list)\n",
    "        else:\n",
    "            print(\"No further reduction possible\")\n",
    "            break\n",
    "        print(curr_pairs)\n",
    "    \n",
    "    \n",
    "def StichPairs(pair_list, level):\n",
    "    \n",
    "    no_of_pairs = len(pair_list)\n",
    "    successful_pairs = []\n",
    "    counter = 0\n",
    "    for i in range(0,no_of_pairs):\n",
    "        # Read files\n",
    "        fname1 = path + 'L'+str(level-1).zfill(2) + '_' + str(pair_list[i][0]).zfill(5) + '.jpg'\n",
    "        fname2 = path + 'L'+str(level-1).zfill(2) + '_' + str(pair_list[i][1]).zfill(5) + '.jpg'\n",
    "        \n",
    "        ## AutoCrop to Eliminate White Spaces\n",
    "        trainImg = imageio.imread(fname1)\n",
    "        trainImg = AutoCrop(trainImg)\n",
    "        trainImg_gray = cv2.cvtColor(trainImg, cv2.COLOR_RGB2GRAY)\n",
    "        queryImg = imageio.imread(fname2)\n",
    "        queryImg = AutoCrop(queryImg)\n",
    "        queryImg_gray = cv2.cvtColor(queryImg, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        tres,s_ratio=Stich(trainImg_gray, queryImg_gray,trainImg,queryImg,feature_extractor)\n",
    "        #tres1,s_ratio1=Stich(queryImg_gray,trainImg_gray,queryImg,trainImg,feature_extractor)\n",
    "\n",
    "        if s_ratio<(1.1):\n",
    "            res = tres\n",
    "            #successful_pairs.append(i)\n",
    "            cv2.imwrite(path + 'L'+str(level).zfill(2) + '_' + str(counter).zfill(5) + '.jpg', tres)\n",
    "            successful_pairs.append(counter)\n",
    "            counter = counter+1\n",
    "        else:\n",
    "            cv2.imwrite(path + 'L'+str(level).zfill(2) + '_' + str(counter).zfill(5) + '.jpg', imageio.imread(fname1))\n",
    "            successful_pairs.append(counter)\n",
    "            counter = counter+1\n",
    "            cv2.imwrite(path + 'L'+str(level).zfill(2) + '_' + str(counter).zfill(5) + '.jpg', imageio.imread(fname2))\n",
    "            successful_pairs.append(counter)\n",
    "            counter = counter+1\n",
    "            \n",
    "    return successful_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def GenPairs(n):\n",
    "    p = []\n",
    "    n_p = int(np.floor(n/2))\n",
    "    for i in range(0, n_p):\n",
    "        p.append((2*i,2*i+1))\n",
    "    if n%2==1:\n",
    "        p.append((2*n_p-1,2*n_p))\n",
    "    return p\n",
    "\n",
    "def Hierarchical(n):\n",
    "    if n<=1:\n",
    "        return\n",
    "    while(n>1):\n",
    "        print(\"Calling: \",n)\n",
    "        print(GenPairs(n))\n",
    "        n = np.floor(n/2.0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video:  20\n",
      "/home/medathati/Work/VideoStiching/VideoFrameSummary/Videos/21_April_Abhilash/_frames_noref20/ No of images:  21\n",
      "Raw matches (Brute force): 920\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 771\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 1569\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 1950\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 2415\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 960\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 1140\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 955\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 532\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 1069\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 1345\n",
      "Shape of: (4, 1, 2)\n",
      "[(1, 2), (3, 4), (5, 6), (7, 8), (9, 10), (11, 12), (13, 14), (15, 16), (17, 18), (19, 20), (20, 21)]\n",
      "Raw matches (Brute force): 581\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 1899\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 1737\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 722\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 663\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 1292\n",
      "Shape of: (4, 1, 2)\n",
      "[(0, 1), (2, 3), (4, 5), (6, 7), (8, 9), (9, 10)]\n",
      "Raw matches (Brute force): 739\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 917\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 1055\n",
      "Shape of: (4, 1, 2)\n",
      "[(0, 1), (2, 3), (4, 5)]\n",
      "Raw matches (Brute force): 1263\n",
      "Shape of: (4, 1, 2)\n",
      "Raw matches (Brute force): 960\n",
      "Shape of: (4, 1, 2)\n",
      "[(0, 1), (1, 2)]\n",
      "Raw matches (Brute force): 2037\n",
      "Shape of: (4, 1, 2)\n",
      "[(0, 1)]\n",
      "CPU times: user 15.6 s, sys: 524 ms, total: 16.1 s\n",
      "Wall time: 9.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "video_folder = '/home/medathati/Work/VideoStiching/VideoFrameSummary/Videos/21_April_Abhilash/'\n",
    "\n",
    "for i in range(20,21):\n",
    "    path = video_folder  + '_frames_noref'+ str(i).zfill(2) + '/'\n",
    "    no_of_files = glob.glob(path + 'L00*.jpg')\n",
    "    print(\"Processing video: \", i)\n",
    "    print(path,'No of images: ',len(no_of_files))\n",
    "    Video2Png(len(no_of_files))\n",
    "    \n",
    "\n",
    "#path = '/home/medathati/Work/VideoStiching/VideoFrameSummary/Videos/_frames2/'\n",
    "#Video2Png(108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrameSelect(im_list):\n",
    "    im_list = np.array(im_list)\n",
    "    level = 1 \n",
    "    no_of_images = len(im_list)\n",
    "    effective_len = np.zeros(no_of_images)\n",
    "    for i in range(0,no_of_images):\n",
    "        # Read files\n",
    "        fname1 = path + 'L'+str(level-1).zfill(2) + '_' + str(im_list[i]).zfill(5) + '.jpg'\n",
    "        ## AutoCrop to Eliminate White Spaces\n",
    "        trainImg = imageio.imread(fname1)\n",
    "        effective_len[i] = AutoCropLen(trainImg)\n",
    "    \n",
    "    d_len = np.diff(effective_len)\n",
    "    d_len[d_len>-20]=0\n",
    "    s_im_list = im_list[np.nonzero(d_len)[0]]\n",
    "    s_im_list = np.concatenate((s_im_list,[im_list[-1]]))\n",
    "    return s_im_list.tolist()\n",
    "\n",
    "im_list = list(range(1,180))\n",
    "d_len = FrameSelect(im_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4   9  13  20  32  34  40  41  43  48  61  67  68  71  74  76 107 109\n",
      " 110 111 118 139 140 141 156 166 167 174]\n"
     ]
    }
   ],
   "source": [
    "print(im_list[np.nonzero(d_len)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12  19  31  33  39  40  42  60  66  67  73  75 106 108 109 110 138 139\n",
      " 140 155 165 166 173]\n"
     ]
    }
   ],
   "source": [
    "print(np.nonzero(d_len)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-623a04ef0683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "c = list(np.nonzero(d_len)[0])\n",
    "im_list[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179,  10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((im_list,[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 4.77 µs\n",
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "a = np.array([0,1,0,0,0,2,3,4,5])\n",
    "b = np.nonzero(a)\n",
    "print(a[b[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0,0,0])\n",
    "print(len(np.nonzero(a)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-94-d77627b182eb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-94-d77627b182eb>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def ExtractBackgroundFrame(im\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def ExtractBackgroundFrame(im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
